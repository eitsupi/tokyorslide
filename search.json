[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "資料",
    "section": "",
    "text": "第91回R勉強会@東京（#TokyoR）LT Rから始めるDocker生活\n第93回R勉強会@東京（#TokyoR）LT rocker/r-verとかのアップデートをちょっと自動化した話\nJapan.R 2021 ショートセッション rocker/r-ver一族のビルドシステムを大改修した話\n第97回R勉強会@東京（#TokyoR）応用セッション Apache Arrowの話"
  },
  {
    "objectID": "tokyor_97/index.html#自己紹介",
    "href": "tokyor_97/index.html#自己紹介",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "自己紹介",
    "text": "自己紹介\n\n\n\n\n\n\n\n\n\n@eitsupi\n製造業勤務\n\nExcelが嫌になりRを触り初めて3年\n\nDockerイメージrocker/r-ver他のメンテナー\nVSCode派\n\nRemote-Containersばかり使っている\n\nこのスライドでQuartoに挑戦"
  },
  {
    "objectID": "tokyor_97/index.html#今日の話",
    "href": "tokyor_97/index.html#今日の話",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "今日の話",
    "text": "今日の話\n\n数十分かけて読み込んでいたCSVファイル群をParquetに置換する際に調べたこと（数十秒～数分で読めるようになった）\nArrowとParquetのことを少しでも知ってもらい、試すきっかけになれば……\n\n\n\n対象かも\n\n✅データはCSVファイル\n✅大量のファイルを読む\n✅読み込みに数十分かかる\n\n\n対象外かも\n\n✅データはDB上\n✅少数のファイルを読む\n✅読み込みは数秒で終わる"
  },
  {
    "objectID": "tokyor_97/index.html#結論",
    "href": "tokyor_97/index.html#結論",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "結論",
    "text": "結論\nQ. CSVをParquetにするとどのくらい早くなる？\n\nA. 場合による（ようなので試してみましょう！）"
  },
  {
    "objectID": "tokyor_97/index.html#apache-parquet",
    "href": "tokyor_97/index.html#apache-parquet",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "Apache Parquet",
    "text": "Apache Parquet\n\n2013年～1\nApache Hadoop用に作られた列指向のファイルフォーマット\n\n列方向に圧縮されるため大量のレコードを圧縮しやすい\n列単位でベクトル化した計算を行う分析処理と相性が良い"
  },
  {
    "objectID": "tokyor_97/index.html#apache-arrow",
    "href": "tokyor_97/index.html#apache-arrow",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "Apache Arrow",
    "text": "Apache Arrow\n\n2016年～2\nA high-performance cross-system data layer for columnar in-memory analytics\n言語に寄らない列指向のインメモリフォーマットの標準を目指しているプロジェクト\n\nArrowを介することで、ある列指向データから別の列指向データへの変換を個別に実装する必要はなくなる"
  },
  {
    "objectID": "tokyor_97/index.html#parquetとfeather",
    "href": "tokyor_97/index.html#parquetとfeather",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "ParquetとFeather",
    "text": "ParquetとFeather\n\n2016年時点でArrowはファイル形式を提供しなかったため、ファイル形式およびそのファイルを読み書きするFeatherライブラリが試験的に作られる\n2020年にArrow IPC (Inter-Process Communication)フォーマットをLZ4かZSTDで圧縮した通称FeatherV2がArrow本体に組み込まれる3\n\nfeatherと呼ばれたりarrowと呼ばれたりipcと呼ばれたり……\n2021年に決まった正式な拡張子は.arrow？4\n\n一方2017年にはParquetをArrowライブラリで読み書きできるようになっており、Parquetの利用が推奨されている5"
  },
  {
    "objectID": "tokyor_97/index.html#arrow-r-package",
    "href": "tokyor_97/index.html#arrow-r-package",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "Arrow R Package",
    "text": "Arrow R Package\n\nパッケージ名はarrow\nApache Arrow C++ライブラリ（libarrow）のRバインディング\nソースインストールするとlibarrowのビルドに長時間がかかることに注意！\nRockerプロジェクトのDockerイメージではrocker/tidyverseにインストール済（なのでこのスライド内のサンプルコードはrocker/tidyverseで動くはず）"
  },
  {
    "objectID": "tokyor_97/index.html#こちらもどうぞ",
    "href": "tokyor_97/index.html#こちらもどうぞ",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "こちらもどうぞ",
    "text": "こちらもどうぞ\n\nそろそろRユーザーもApache ArrowでParquetを使ってみませんか？ 2019-12-17\n「CSVをやめて人間を続けよう」\nNew Directions for Apache Arrow 2021-09-10\nWes McKinney氏によるNew York R Conferenceでの発表資料\nApache ArrowによるRubyのデータ処理対応の可能性 2022-02\n日本語でArrowについて詳しく説明された論文"
  },
  {
    "objectID": "tokyor_97/index.html#ファイルの読み書き",
    "href": "tokyor_97/index.html#ファイルの読み書き",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "ファイルの読み書き",
    "text": "ファイルの読み書き\narrowパッケージは独自にファイルを読み書きする関数を持っている\n\n\nTable 1: データ読み込み関数の比較\n\n\n対象ファイル\n数\nutils\nreadr\narrow\n\n\n\n\ncsv\n単体\nread.csv\nread_csv\nread_csv_arrow\n\n\ncsv\n複数\n-\nread_csv\nopen_dataset\n\n\nparquet\n単体\n-\n-\nread_parquet\n\n\nparquet\n複数\n-\n-\nopen_dataset"
  },
  {
    "objectID": "tokyor_97/index.html#csvの読み込み-13",
    "href": "tokyor_97/index.html#csvの読み込み-13",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "CSVの読み込み　1/3",
    "text": "CSVの読み込み　1/3\n\nfile_csv <- readr::readr_example(\"mtcars.csv\")\n\narrow::read_csv_arrow(file_csv, as_data_frame = FALSE)\n\nTable\n32 rows x 11 columns\n$mpg <double>\n$cyl <int64>\n$disp <double>\n$hp <int64>\n$drat <double>\n$wt <double>\n$qsec <double>\n$vs <int64>\n$am <int64>\n$gear <int64>\n$carb <int64>\n\n\n\nas_data_frame引数はRのdata.frameに変換するかarrow::Tableのままにするかを制御する（デフォルトはTRUE）"
  },
  {
    "objectID": "tokyor_97/index.html#csvの読み込み-23",
    "href": "tokyor_97/index.html#csvの読み込み-23",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "CSVの読み込み　2/3",
    "text": "CSVの読み込み　2/3\n同じ列構造を持つ複数ファイルを読み込みたい場合はopen_dataset()によりデータセットとして開く\n\nc(file_csv, file_csv) |> arrow::open_dataset(format = \"csv\")\n\nFileSystemDataset with 2 csv files\nmpg: double\ncyl: int64\ndisp: double\nhp: int64\ndrat: double\nwt: double\nqsec: double\nvs: int64\nam: int64\ngear: int64\ncarb: int64\n\n\n\nこの段階では矩形データの構造（スキーマ）を読み込んだだけで、データ全体を読み込んではいない"
  },
  {
    "objectID": "tokyor_97/index.html#csvの読み込み-33",
    "href": "tokyor_97/index.html#csvの読み込み-33",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "CSVの読み込み　3/3",
    "text": "CSVの読み込み　3/3\ncomputeかcollectでデータをメモリ上に読み込む\n\nds <- c(file_csv, file_csv) |> arrow::open_dataset(format = \"csv\")\n\n\n\n\nTable\n\nds |> dplyr::compute()\n\nTable\n64 rows x 11 columns\n$mpg <double>\n$cyl <int64>\n$disp <double>\n$hp <int64>\n$drat <double>\n$wt <double>\n$qsec <double>\n$vs <int64>\n$am <int64>\n$gear <int64>\n$carb <int64>\n\n\n\ndata.frame\n\nds |> dplyr::collect()\n\n# A tibble: 64 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   <dbl> <int> <dbl> <int> <dbl> <dbl> <dbl> <int> <int> <int> <int>\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# … with 54 more rows"
  },
  {
    "objectID": "tokyor_97/index.html#parquetファイルの読み込み-12",
    "href": "tokyor_97/index.html#parquetファイルの読み込み-12",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "Parquetファイルの読み込み　1/2",
    "text": "Parquetファイルの読み込み　1/2\nwrite_parquetでParquetファイルを書き込んで、read_parquetで読み込む\n\narrow::write_parquet(mtcars, \"mtcars.parquet\")\n\narrow::read_parquet(\"mtcars.parquet\", as_data_frame = FALSE)\n\nTable\n32 rows x 11 columns\n$mpg <double>\n$cyl <double>\n$disp <double>\n$hp <double>\n$drat <double>\n$wt <double>\n$qsec <double>\n$vs <double>\n$am <double>\n$gear <double>\n$carb <double>\n\nSee $metadata for additional Schema metadata"
  },
  {
    "objectID": "tokyor_97/index.html#parquetファイルの読み込み-22",
    "href": "tokyor_97/index.html#parquetファイルの読み込み-22",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "Parquetファイルの読み込み　2/2",
    "text": "Parquetファイルの読み込み　2/2\nParquetの場合も複数ファイルの場合はopen_datasetを使う\nformat引数のデフォルトは\"parquet\"なので指定しなくてもよい\n\nc(\"mtcars.parquet\", \"mtcars.parquet\") |>\n  arrow::open_dataset(format = \"parquet\") |>\n  dplyr::compute()\n\nTable\n64 rows x 11 columns\n$mpg <double>\n$cyl <double>\n$disp <double>\n$hp <double>\n$drat <double>\n$wt <double>\n$qsec <double>\n$vs <double>\n$am <double>\n$gear <double>\n$carb <double>\n\nSee $metadata for additional Schema metadata"
  },
  {
    "objectID": "tokyor_97/index.html#dplyrの基本おさらい",
    "href": "tokyor_97/index.html#dplyrの基本おさらい",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "dplyrの基本おさらい",
    "text": "dplyrの基本おさらい\n多くの関数はdata.frameを第一引数にとりdata.frameを返す\n\nclass(mtcars)\n\n[1] \"data.frame\"\n\nclass(dplyr::select(mtcars, cyl))\n\n[1] \"data.frame\"\n\n\n\nもしくはパイプ演算子を使って\n\nmtcars |>\n  dplyr::select(cyl) |>\n  class()\n\n[1] \"data.frame\""
  },
  {
    "objectID": "tokyor_97/index.html#arrow_dplyr_query",
    "href": "tokyor_97/index.html#arrow_dplyr_query",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "arrow_dplyr_query",
    "text": "arrow_dplyr_query\nTableやDatasetをそれらのdplyrの関数の第一引数に渡すとarrow_dplyr_queryクラスオブジェクトが返ってくる\n\narrow::open_dataset(\"mtcars.parquet\") |>\n  dplyr::select(cyl) |>\n  class()\n\n[1] \"arrow_dplyr_query\"\n\n\n\n\narrow_dplyr_queryを第一引数に渡した場合も同じ挙動\n\ndata.frameのようにパイプラインを繋げていける\n\ncomputeかcollectに渡すとクエリが実行される（dbplyrに類似）\n\nArrowインメモリフォーマットのままdplyrで記述した処理を実行できる"
  },
  {
    "objectID": "tokyor_97/index.html#遅延評価",
    "href": "tokyor_97/index.html#遅延評価",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "遅延評価",
    "text": "遅延評価\nデータセットはcomputeかcollectに繋げるまで読み込まれない\nc(\"mtcars.parquet\", \"mtcars.parquet\") |>\n  arrow::open_dataset(format = \"parquet\") |>\n  dplyr::collect()"
  },
  {
    "objectID": "tokyor_97/index.html#遅延評価-1",
    "href": "tokyor_97/index.html#遅延評価-1",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "遅延評価",
    "text": "遅延評価\nクエリもcomputeかcollectに繋げるまで評価されない\nc(\"mtcars.parquet\", \"mtcars.parquet\") |>\n  arrow::open_dataset(format = \"parquet\") |>\n  dplyr::filter(cyl == 6) |>\n  dplyr::select(dplyr::starts_with(\"d\")) |>\n  dplyr::collect()\n\n\ndplyrクエリはarrowパッケージによって翻訳されlibarrowがクエリを実行する\n翻訳可能な関数はarrowに登録されているもののみなので、非対応の関数を含めるとエラーになる（データセットに対するクエリの場合）\n対応している関数は徐々に増えており、NEWSで確認可能"
  },
  {
    "objectID": "tokyor_97/index.html#プッシュダウン",
    "href": "tokyor_97/index.html#プッシュダウン",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "プッシュダウン",
    "text": "プッシュダウン\nクエリもcomputeかcollectに繋げるまで評価されない\nc(\"mtcars.parquet\", \"mtcars.parquet\") |>\n  arrow::open_dataset(format = \"parquet\") |>\n  dplyr::filter(cyl == 6) |>\n  dplyr::select(dplyr::starts_with(\"d\")) |>\n  dplyr::collect()\n\n\nParquetデータセットに対してクエリを実行するとき、クエリを解析し必要な列と行のみをファイルから読み込む（プッシュダウン）\n\nCSVと比べた場合のParquetの大きな利点\n\n読み込むデータの少ないほど読み込み時間は短縮される\n読み込むデータの少ないほど省メモリで処理できる"
  },
  {
    "objectID": "tokyor_97/index.html#実行結果",
    "href": "tokyor_97/index.html#実行結果",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "実行結果",
    "text": "実行結果\nクエリもcomputeかcollectに繋げるまで評価されない\n\nc(\"mtcars.parquet\", \"mtcars.parquet\") |>\n  arrow::open_dataset(format = \"parquet\") |>\n  dplyr::filter(cyl == 6) |>\n  dplyr::select(dplyr::starts_with(\"d\")) |>\n  dplyr::collect()\n\n    disp drat\n1  160.0 3.90\n2  160.0 3.90\n3  258.0 3.08\n4  225.0 2.76\n5  167.6 3.92\n6  167.6 3.92\n7  145.0 3.62\n8  160.0 3.90\n9  160.0 3.90\n10 258.0 3.08\n11 225.0 2.76\n12 167.6 3.92\n13 167.6 3.92\n14 145.0 3.62"
  },
  {
    "objectID": "tokyor_97/index.html#データセットの作成",
    "href": "tokyor_97/index.html#データセットの作成",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "データセットの作成",
    "text": "データセットの作成\n列の値毎に分割した複数のParquetファイルをデータセットとして書き込める（パーティショニング）\nfs::dir_create(\"test_data\")\n\nc(\"mtcars.parquet\") |>\n  arrow::open_dataset(format = \"parquet\") |>\n  arrow::write_dataset(\"test_data\", partitioning = \"cyl\")\n\nなお上記のようにデータセットからデータセットに直接変換する場合等はバッチ毎に逐次処理されるので、メモリに乗り切らないデータを加工可能6……かもしれない7"
  },
  {
    "objectID": "tokyor_97/index.html#hive-style-パーティション",
    "href": "tokyor_97/index.html#hive-style-パーティション",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "Hive-style パーティション",
    "text": "Hive-style パーティション\nfs::dir_create(\"test_data\")\narrow::write_dataset(mtcars, \"test_data\", partitioning = \"cyl\")\n上のコードを実行すると以下のような複数のディレクトリとParquetファイルが生成される\n$ tree test_data\ntest_data\n├── cyl=4\n│   └── part-0.parquet\n├── cyl=6\n│   └── part-0.parquet\n└── cyl=8\n    └── part-0.parquet\n\n3 directories, 3 files\nParquetファイルにはcyl列が含まれておらず代わりにディレクトリ名がkey=valueの形式になっている"
  },
  {
    "objectID": "tokyor_97/index.html#パーティショニングを利用する場合の注意",
    "href": "tokyor_97/index.html#パーティショニングを利用する場合の注意",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "パーティショニングを利用する場合の注意",
    "text": "パーティショニングを利用する場合の注意\n\nParquetファイルのサイズとパーティション数8\nそのまま読み込み可能なツールは限られる\n\n⭕ pyarrow (PythonのArrow公式ライブラリ)\n❌ polars\n❌ duckdb\n❌ Parquet.jl\n\n\n>>> import pyarrow.dataset as ds\n>>> ds.dataset(\"test_data\", partitioning=\"hive\")\n<pyarrow._dataset.FileSystemDataset object at 0x7f1162853730>"
  },
  {
    "objectID": "tokyor_97/index.html#dplyrクエリ中での型変更",
    "href": "tokyor_97/index.html#dplyrクエリ中での型変更",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "dplyrクエリ中での型変更",
    "text": "dplyrクエリ中での型変更\nas.integer等の一般的な関数は登録済みのものが多い\n任意のArrowタイプに変換するにはmutate等の中でcastを使用する\ncastは単体の関数として存在しないため、ヘルプを検索してもヒットしない\n\nmtcars |>\n  arrow::arrow_table() |>\n  dplyr::transmute(cyl = cast(cyl, arrow::int8())) |>\n  dplyr::compute()\n\nTable\n32 rows x 1 columns\n$cyl <int8>\n\nSee $metadata for additional Schema metadata"
  },
  {
    "objectID": "tokyor_97/index.html#duckdb",
    "href": "tokyor_97/index.html#duckdb",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "DuckDB",
    "text": "DuckDB\n\n2019年～9\nしばしば The SQLite for Analytics と紹介されている、SQLiteのような使い勝手を目指した列指向の分析用RDBMS\nParquetファイル（複数可）に対してクエリを実行できる\n\n現段階ではHiveスタイルのパーティションには非対応\nSnappy圧縮のみ対応\n\nシングルバイナリのCLIや、公式Python、Rパッケージ等から実行\n\nPythonとRにはArrowとDuckDBの相互変換機能があり、Arrowオブジェクトに対してDuckDBのクエリを実行可能10"
  },
  {
    "objectID": "tokyor_97/index.html#to_arrowとto_duckdb",
    "href": "tokyor_97/index.html#to_arrowとto_duckdb",
    "title": "Apache Arrow 鬼はええ！このままCSV全部Parquetに変換していこうぜ！",
    "section": "to_arrowとto_duckdb",
    "text": "to_arrowとto_duckdb\ndplyrのパイプライン中でarrowとduckdbのクエリを相互切り替え可能\narrow7.0.0の対応していないslice_minをduckdb側で処理する例\n\narrow::open_dataset(\"mtcars.parquet\") |>\n  dplyr::select(mpg, cyl) |>\n  dplyr::group_by(cyl) |>\n  arrow::to_duckdb() |>\n  dplyr::slice_min(mpg, n = 3) |>\n  arrow::to_arrow() |>\n  dplyr::compute()\n\nTable\n10 rows x 2 columns\n$mpg <double>\n$cyl <double>\n\n\n\narrowから見たメリット：非対応クエリをduckdb側で処理できる\nduckdbから見たメリット：arrowのファイル読み込みを利用できる"
  }
]