---
title: "Apache Arrow 鬼はええ！"
subtitle: "このままCSV全部Parquetに変換していこうぜ！"
format:
  revealjs:
    theme: [night, custom.scss]
    width: 1280
    height: 720
    slide-number: true
    chalkboard: false
    preview-links: auto
    footer: "#TokyoR"
    self-contained: false
    # output-file: "../tokyor_97/index.html"
engine: knitr
---

# はじめに

## 自己紹介

![](../image/eitsupi.jpg){fig-align="center" width="300" height="300"}

- [@eitsupi](https://twitter.com/eitsupi)
- 製造業勤務
- Dockerイメージ`rocker/r-ver`他のメンテナー

## 今日の話……

:::: {.columns}
::: {.column width="50%"}
### 対象かも

✅データはCSVファイル  
✅大量のファイルを読む  
✅読み込みに時間かかる
:::

::: {.column width="50%"}
### 対象外かも

✅データはDB上  
✅少数のファイルを読む  
✅読み込みに困っていない
:::
::::

## 結論


# Apache Arrowについて

## Apache Arrowプロジェクト

## インメモリフォーマット

## Apache Parquet

## Arrow R Package

# Arrow R Packageの基本機能

## ファイルの読み書き

`arrow`パッケージは独自にファイルを読み書きする関数を持っている。  
他パッケージとの対応関係は以下の通り。

| 対象ファイル | 数   |  utils   |                               readr                               |                                       arrow                                       |
| ------------ | ---- | :------: | :---------------------------------------------------------------: | :-------------------------------------------------------------------------------: |
| csv          | 単体 | read.csv | [read_csv](https://readr.tidyverse.org/reference/read_delim.html) | [read_csv_arrow](https://arrow.apache.org/docs/r/reference/read_delim_arrow.html) |
| csv          | 複数 |    -     |                             read_csv                              |    [open_dataset](https://arrow.apache.org/docs/r/reference/open_dataset.html)    |
| parquet      | 単体 |    -     |                                 -                                 |    [read_parquet](https://arrow.apache.org/docs/r/reference/read_parquet.html)    |
| parquet      | 複数 |    -     |                                 -                                 |                                   open_dataset                                    |

## CSVの読み込み　1/2

`read_csv`と`read_csv_arrow`は同じ結果になるか確認してみる。

```{r}
#| echo: true
#| code-line-numbers: "|6-7"
file_csv <- readr::readr_example("mtcars.csv")

df_readr <- file_csv |>
  readr::read_csv()

df_arrow_csv <- file_csv |>
  arrow::read_csv_arrow(as_data_frame = TRUE)
```

::: {.incremental}
- `as_data_frame`引数はRの`data.frame`に変換するか`arrow::Table`のままにするかを制御する。  
  （デフォルトは`TRUE`）
:::

## CSVの読み込み　2/2

`read_csv`と`read_csv_arrow`で読んだデータフレームを比較すると……

```{r}
#| echo: true
dplyr::all_equal(df_readr, df_arrow_csv)
```

**同じ内容になっていなかった。**

::: {.incremental}
- CSV辛い
  - CSVの文字列をどのように解釈するかはプログラム次第。
  - 型指定通りに文字列を解釈できるとは限らない。  
    （特に複数ファイル対象時）
:::

## Parquetファイルの読み込み　1/3

CSVファイルをParquetファイルに変換し、その後Parquetファイルを読み込んでみる。

```{r}
#| echo: true
arrow::read_csv_arrow(readr::readr_example("mtcars.csv"), as_data_frame = FALSE) |>
  arrow::write_parquet("mtcars.parquet")

df_arrow_pq <- arrow::read_parquet("mtcars.parquet", as_data_frame = TRUE)
```

RでのParquetの読み込みは`duckdb`パッケージでも可能なので、比較対象としてこちらでも読み込む。

```{r}
#| echo: true
con <- DBI::dbConnect(duckdb::duckdb())
df_duckdb_pq <- DBI::dbGetQuery(con, "select * from parquet_scan('mtcars.parquet')")
DBI::dbDisconnect(con)
```

## Parquetファイルの読み込み　2/3

二つのデータフレームを比較すると……

```{r}
#| echo: true
dplyr::all_equal(df_arrow_pq, df_duckdb_pq)
```

やっぱり同じじゃねーじゃねーか！

::::{.columns}
:::{.column width="50%"}
```{r}
#| echo: true
arrow::read_parquet(
  "mtcars.parquet",
  as_data_frame = FALSE
)
```
:::
:::{.column width="50%"}
```{python}
#| echo: true
import pyarrow.parquet as pq
pq.read_table("mtcars.parquet")
```
:::
::::

<!-- 一時ファイル削除 -->
```{r}
fs::file_delete("mtcars.parquet")
```


```{.r}
library(tidyverse)

df_1 <- data.frame(
  col_1 = c(1, 2),
  col_2 = c("a", "b")
)

df_2 <- df_1 |>
  dplyr::select(col_2, col_1)

df_1 |>
  readr::write_csv("1.csv")

df_2 |>
  readr::write_csv("2.csv")

readr::read_csv(
  c("1.csv", "2.csv")
)

arrow::open_dataset(
  c("1.csv", "2.csv"),
  format = "csv"
)

data.frame(
  col_1 = c(1:10000, "あ"),
  col_2 = "c"
) |>
  write_csv("3.csv")
```
